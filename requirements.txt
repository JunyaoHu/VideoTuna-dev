deepspeed==0.15.4
av==12.3.0
beautifulsoup4==4.12.3
colossalai==0.4.0
decord==0.6.0
einops==0.8.0
fire==0.6.0
torch==2.2.2
ftfy==6.2.3
huggingface_hub==0.24.6
imwatermark==0.0.2
kornia==0.7.3
mmengine==0.10.4
omegaconf==2.3.0
opencv_python==4.10.0.84
packaging==24.1
pandas==2.2.2
Pillow==10.4.0
pudb==2024.1.2
pytorch_lightning==2.4.0
PyYAML==6.0.2
rotary_embedding_torch==0.6.5
Requests==2.32.3
safetensors==0.4.4
timm==1.0.8
torchvision==0.17.2
tqdm==4.66.5
transformers==4.39.3
xformers==0.0.25.post1
imageio==2.35.1
imageio-ffmpeg==0.5.1
pyramid==1.5
wandb==0.17.8
scipy==1.14.1
beartype==0.18.5
numpy==1.*
https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.2cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
git+https://github.com/huggingface/diffusers
open_clip_torch==2.12.0
lmdeploy
moviepy
