flow:
  target: videotuna.flow.hunyuanvideo.HunyuanVideoFlow
  params:
    args:
      # Model Configuration
      model: HYVideo-T/2
      latent_channels: 16
      precision: bf16
      rope_theta: 256
      gradient_checkpoint: false
      gradient_checkpoint_layers: -1

      # VAE Configuration
      vae: 884-16c-hy
      vae_precision: fp16
      vae_tiling: true

      # Text Encoder Settings
      text_encoder: llm-i2v
      text_encoder_precision: fp16
      text_states_dim: 4096
      text_len: 256
      tokenizer: llm-i2v
      prompt_template: dit-llm-encode-i2v
      prompt_template_video: dit-llm-encode-video-i2v
      hidden_state_skip_layer: 2
      apply_final_norm: false

      # Secondary Text Encoder
      text_encoder_2: clipL
      text_encoder_precision_2: fp16
      text_states_dim_2: 768
      tokenizer_2: clipL
      text_len_2: 77

      # Diffusion Parameters
      denoise_type: flow
      flow_shift: 7.0
      flow_reverse: true
      flow_solver: euler
      use_linear_quadratic_schedule: false
      linear_schedule_end: 25

      # Image-to-Video Settings
      i2v_mode: true
      i2v_resolution: 720p
      i2v_image_path: assets/demo/i2v/imgs/0.jpg
      i2v_condition_type: token_replace
      i2v_stability: true

      # LoRA Settings
      use_lora: false
      lora_path: ''
      lora_scale: 1.0
      lora_rank: 64

      # Path Settings
      model_base: /project/llmsvgen/songsong/checkpoints/hunyuan/HunyuanVideo-I2V
      dit_weight: ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt
      i2v_dit_weight: /project/llmsvgen/songsong/checkpoints/hunyuan/HunyuanVideo-I2V/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt
      model_resolution: 540p
      load_key: module

      # Inference Settings
      use_cpu_offload: true
      batch_size: 1
      infer_steps: 50
      disable_autocast: false
      save_path: ./results
      save_path_suffix: ''
      name_suffix: ''
      num_videos: 1
      video_size: [720, 1280]
      video_length: 129
      prompt: An Asian man with short hair in black tactical uniform and white clothes waves a firework stick.
      seed_type: auto
      seed: 0
      neg_prompt: null
      cfg_scale: 1.0
      embedded_cfg_scale: 6.0

      # Advanced Settings
      use_fp8: false
      reproduce: false
      ulysses_degree: 1
      ring_degree: 1
      xdit_adaptive_size: false
      
    ckpt_path: /project/llmsvgen/songsong/checkpoints/hunyuan/HunyuanVideo-I2V
    denoiser_ckpt_path: ${flow.params.ckpt_path}/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt
    first_stage_ckpt_path: ${flow.params.ckpt_path}/hunyuan-video-i2v-720p/vae

    first_stage_config:
      target: videotuna.hunyuan.hyvideo_i2v.vae.autoencoder_kl_causal_3d.AutoencoderKLCausal3D
      params:
        act_fn: "silu"
        block_out_channels: [
          128,
          256,
          512,
          512
        ]
        down_block_types: [
          "DownEncoderBlockCausal3D",
          "DownEncoderBlockCausal3D",
          "DownEncoderBlockCausal3D",
          "DownEncoderBlockCausal3D"
        ]
        in_channels: 3
        latent_channels: 16
        layers_per_block: 2
        norm_num_groups: 32
        out_channels: 3
        sample_size: 256
        sample_tsize: 64
        up_block_types: [
          "UpDecoderBlockCausal3D",
          "UpDecoderBlockCausal3D",
          "UpDecoderBlockCausal3D",
          "UpDecoderBlockCausal3D"
        ]
        scaling_factor: 0.476986
        time_compression_ratio: 4
        mid_block_add_attention: true
    
    cond_stage_config:
      target: videotuna.hunyuan.hyvideo_i2v.text_encoder.TextEncoder
      params:
        prompt_template:
          template: "<|start_header_id|>system<|end_header_id|>\n\n<image>\nDescribe the image by detailing the color, shape, size, texture, quantity, text, spatial relationships of the objects and background:<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
          crop_start: 36
          image_emb_start: 5
          image_emb_end: 581
          image_emb_len: 576
          double_return_token_id: 271
    
        prompt_template_video:
          template: '<|start_header_id|>system<|end_header_id|>\n\n<image>\nDescribe the video by detailing the following aspects according to the reference image: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eot_id|>\n\n<|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'
          crop_start: 103
          image_emb_start: 5
          image_emb_end: 581
          image_emb_len: 576
          double_return_token_id: 271

        text_encoder_type: llm-i2v
        max_length: 359
        text_encoder_precision: fp16
        text_encoder_path: null
        tokenizer_type: llm-i2v
        tokenizer_path: null
        output_key: null
        use_attention_mask: true
        i2v_mode: true
        input_max_length: null
        hidden_state_skip_layer: 2
        apply_final_norm: false
        reproduce: false
        device: cpu
        image_embed_interleave: 4

    cond_stage_2_config:
      target: videotuna.hunyuan.hyvideo_i2v.text_encoder.TextEncoder
      params:
        text_encoder_type: clipL
        max_length: 77
        text_encoder_precision: fp16
        text_encoder_path: null
        tokenizer_type: clipL
        tokenizer_path: null
        output_key: null
        use_attention_mask: true
        i2v_mode: false
        input_max_length: null
        hidden_state_skip_layer: null
        apply_final_norm: false
        reproduce: false
        device: cpu
        image_embed_interleave: null
    
    # Denosier model
    denoiser_config:
      target: videotuna.hunyuan.hyvideo_i2v.modules.models.HYVideoDiffusionTransformer
      params:
        i2v_condition_type: 'token_replace'
        text_states_dim: 4096
        text_states_dim_2: 768
        gradient_checkpoint: False
        gradient_checkpoint_layers: -1

        patch_size: [1, 2, 2]
        in_channels: 16         # Should be VAE.config.latent_channels.
        out_channels: 16
        hidden_size: 3072
        heads_num: 24
        mlp_width_ratio: 4.0
        mlp_act_type: "gelu_tanh"
        mm_double_blocks_depth: 20
        mm_single_blocks_depth: 40
        rope_dim_list: [16, 56, 56]
        qkv_bias: true
        qk_norm: true
        qk_norm_type: "rms"
        guidance_embed: false  # For modulation.
        text_projection: "single_refiner"
        use_attention_mask: true
        dtype: ${dtype_resolver:torch.bfloat16}
        device: cpu
    

    # # Diffusion sampling scheduler
    scheduler_config:
      target: videotuna.hunyuan.hyvideo_i2v.diffusion.schedulers.scheduling_flow_match_discrete.FlowMatchDiscreteScheduler
      params:
        shift: 7.0
        reverse: True
        solver: 'euler'




inference:
  ckpt_path: /project/llmsvgen/songsong/DiffSynth-Studio/models/stepfun-ai/stepvideo-t2v
  mode: t2v
  savedir: results/t2v/videocrafter2
  seed: 42
  height: 544
  width: 992
  num_frames: 204 
  num_inference_steps: 5
  n_samples_prompt: 1
  time_shift: 13.0
  bs: 1
  ddim_steps: 1
  ddim_eta: 1.0
  unconditional_guidance_scale: 12.0
  fps: 1
  prompts: '一名宇航员在月球上发现一块石碑，上面印有“stepfun”字样，闪闪发光'
    

