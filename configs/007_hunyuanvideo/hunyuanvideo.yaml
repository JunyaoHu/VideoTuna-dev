model:
  base_learning_rate: 6e-6
  target: videotuna.hunyuanvideo.hunyuanvideo.HunyuanVideoWorkFlow
  params: 
    # VAE of HunyuanVideo
    first_stage_config:
      target: videotuna.hunyuanvideo.vae.autoencoder_kl_causal_3d.AutoencoderKLCausal3D
      # seems we do not need params here, defaults look fine. 
      # params:
        # pretrained_model_name_or_path: checkpoints-local/hunyuanvideo/hunyuan-video-t2v-720p/vae
      #   subfolder: "vae"
    
    # Text encoder 
    cond_stage_config:
      target: videotuna.hunyuanvideo.text_encoder.TextEncoder # TODO
      params:
        text_encoder_type: "llm"
        device: "cuda"
        max_length: 226 
        # freeze: True
    
    # Denosier model
    denoiser_config:
      target: videotuna.hunyuanvideo.modules.models.HYVideoDiffusionTransformer
      params:
        # dtype: "bf16" # bf16 5b / fp16 2B 
        # revision: null 
        # variant: null
        args:
          model: "HYVideo-T/2-cfgdistill"
          latent-channels: 16
          precision: "bf16"
          rope-theta: 256
          text_states_dim: 4096
          text_states_dim_2: 768
        in_channels: 16
        out_channels: 16
        device: "cuda"
        dtype: "bf16"
        
    
    # Lora module 
    adapter_config: 
      target: peft.LoraConfig
      params:
        r: 4
        lora_alpha: 1.0 
        init_lora_weights: True
        target_modules: ["to_k", "to_q", "to_v", "to_out.0"]

    # Diffusion sampling scheduler
    scheduler_config:
      target: videotuna.hunyuanvideo.diffusion.schedulers.scheduling_flow_match_discrete
      # params:
        # pretrained_model_name_or_path: checkpoints/cogvideo/CogVideoX-5b
        # subfolder: scheduler

# data configs
data:
  target: videotuna.data.lightning_data.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 16
    wrap: false
    train:
      target: videotuna.data.cogvideo_dataset.VideoDataset
      params:
        instance_data_root: "inputs/t2v/hunyuanvideo/tyler_swift_video"
        dataset_name: null 
        dataset_config_name: null
        caption_column: "labels.txt"
        video_column: "videos.txt"
        height: 480
        width: 720
        fps: 28
        max_num_frames: 2
        skip_frames_start: 0
        skip_frames_end: 0
        cache_dir: ~/.cache
        id_token: null

# training configs
lightning:
  trainer:
    benchmark: True
    num_nodes: 1
    accumulate_grad_batches: 2
    max_epochs: 2000
    precision: 32
  callbacks:
    image_logger:
      target: videotuna.utils.callbacks.ImageLogger
      params:
        batch_frequency: 100000
        max_images: 2
        to_local: True # save videos into local files
        log_images_kwargs:
          unconditional_guidance_scale: 6
    metrics_over_trainsteps_checkpoint:
      target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        filename: "{epoch:06}-{step:09}"
        save_weights_only: False
        # every_n_epochs: 300
        every_n_train_steps: 10
    

